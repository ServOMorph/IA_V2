ğŸ§ª PROTOCOLE DE TEST â€“ IA Locale Mistral via Ollama

ğŸ¯ OBJECTIFS DU PROTOCOLE
----------------------------
1. Mesurer les TEMPS DE RÃ‰PONSE Ã  diffÃ©rents types de prompts.
2. Ã‰valuer la QUALITÃ‰ DES RÃ‰PONSES (cohÃ©rence, pertinence, style).
3. Tester la STABILITÃ‰ de l'application face Ã  des cas extrÃªmes.
4. Identifier les LIMITES du modÃ¨le (raisonnement, gÃ©nÃ©ration).
5. GÃ©nÃ©rer un RAPPORT SYNTHÃ‰TIQUE des performances.


ğŸ“ STRUCTURE DES FICHIERS ASSOCIÃ‰S
-------------------------------------
- questions_IA.txt â†’ prompts classÃ©s par type
- test_performance.py â†’ script de test automatisÃ©
- resultats_test.csv â†’ journal des temps et rÃ©ponses
- notes_subjectives.txt (optionnel) â†’ apprÃ©ciations manuelles
- debug.log & historique.txt â†’ suivis techniques internes


ğŸ§© Ã‰TAPES DU TEST
====================

1. âš¡ TEST TEMPS DE RÃ‰PONSE
--------------------------------
- Mesurer le dÃ©lai entre envoi et rÃ©ception pour chaque prompt.
- Utiliser `time.perf_counter()` pour une prÃ©cision milliseconde.
- Calculer : moyenne, minimum, maximum, Ã©cart-type.
- Tester sur :
    â€¢ 10 prompts simples
    â€¢ 10 prompts complexes
    â€¢ 5 prompts trÃ¨s longs
    â€¢ 5 prompts en rafale (envoyÃ©s rapidement)

2. ğŸ§  TEST QUALITÃ‰ DES RÃ‰PONSES
-----------------------------------
Ã‰valuer manuellement ou automatiquement selon les critÃ¨res :
- Prompts simples â†’ rÃ©ponse claire, syntaxe correcte
- Prompts techniques â†’ exactitude des faits
- Prompts rÃ©dactionnels â†’ fluiditÃ© du texte
- Prompts piÃ©geux â†’ capacitÃ© de raisonnement/logique

Notation suggÃ©rÃ©e : sur 5 (ClartÃ©, Pertinence, FluiditÃ©)

3. ğŸ”„ TEST DE ROBUSTESSE
-------------------------------
Soumettre des entrÃ©es inhabituelles ou invalides :
- ChaÃ®nes vides
- Texte uniquement composÃ© de symboles ou emojis
- JSON malformÃ© ou code incomplet
- Envoi rapide de plusieurs prompts simultanÃ©ment
Objectif : repÃ©rer des crashs, erreurs API, blocages ou lenteurs.

4. ğŸ§± TEST DES LIMITES DU MODÃˆLE
------------------------------------
Tester les capacitÃ©s dâ€™abstraction et de crÃ©ativitÃ© :
- GÃ©nÃ©ration de code
- RÃ©solution dâ€™Ã©nigmes
- RÃ©sumÃ©s complexes
- CrÃ©ation dâ€™histoires longues avec structure

5. ğŸ§¾ GÃ‰NÃ‰RATION Dâ€™UN RAPPORT
----------------------------------
Ã€ la fin des tests :
- CrÃ©er le fichier `resultats_test.csv` avec colonnes :
    [Horodatage, Type, Prompt, DurÃ©e(ms), Longueur rÃ©ponse, RÃ©ponse tronquÃ©e]
- Calculer :
    â€¢ Temps moyen par type de prompt
    â€¢ Taux dâ€™erreurs (Ã©checs API, dÃ©lais excessifs)
    â€¢ Taille moyenne des rÃ©ponses
- RÃ©sumer manuellement les observations dans `notes_subjectives.txt` :
    - Forces du modÃ¨le
    - Faiblesses dÃ©tectÃ©es
    - Cas particuliers


ğŸ“Œ CONSEILS POUR Lâ€™UTILISATION
----------------------------------
- Utiliser un CPU/GPU constant pour tous les tests
- Fermer les autres applications pour limiter le bruit
- Nettoyer `debug.log` et `historique.txt` avant chaque test complet
- Lancer les tests au calme pour Ã©viter des biais rÃ©seau ou mÃ©moire

ğŸ“ REMARQUES FINALES
------------------------
- Ce protocole est gÃ©nÃ©rique et peut Ãªtre rÃ©utilisÃ© avec d'autres modÃ¨les.
- Il est extensible pour des tests NLP, vision, ou multi-modaux.
