# ğŸ§  ServOMorph â€“ IA_V2

Interface graphique simple en Python (Kivy) pour interagir avec un modÃ¨le dâ€™intelligence artificielle local via Ollama (ex. Mistral).

---

## ğŸš€ FonctionnalitÃ©s

- Interface utilisateur en Kivy (champ de texte, rÃ©ponses, boutons).
- IntÃ©gration avec un serveur Ollama local (ex. modÃ¨le `mistral`).
- Enregistrement automatique de chaque Ã©change dans `historique.txt`.
- Nettoyage de la console : seulement les infos utiles (prompts, rÃ©ponses, erreurs).
- Position personnalisÃ©e de la fenÃªtre (gauche-centre de l'Ã©cran).
- Architecture modulaire prÃªte pour Ã©voluer.

---

## ğŸ› ï¸ PrÃ©requis

- Python 3.11+
- Ollama installÃ© localement avec un modÃ¨le compatible (ex. `mistral`)

---

## ğŸ”§ Installation

1. Cloner le dÃ©pÃ´t :
   ```bash
   git clone https://github.com/votre-utilisateur/IA_V2.git
   cd IA_V2


## â–¶ï¸ Lancement du programme
- Lancer le script batch pour dÃ©marrer Ollama avec le modÃ¨le : - lancement_Mistral_Ollama.bat
- ExÃ©cuter le programme principal : python main.py

