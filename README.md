# 🧠 ServOMorph – IA_V2

Interface graphique simple en Python (Kivy) pour interagir avec un modèle d’intelligence artificielle local via Ollama (ex. Mistral).

---

## 🚀 Fonctionnalités

- Interface utilisateur en Kivy (champ de texte, réponses, boutons).
- Intégration avec un serveur Ollama local (ex. modèle `mistral`).
- Enregistrement automatique de chaque échange dans `historique.txt`.
- Nettoyage de la console : seulement les infos utiles (prompts, réponses, erreurs).
- Position personnalisée de la fenêtre (gauche-centre de l'écran).
- Architecture modulaire prête pour évoluer.

---

## 🛠️ Prérequis

- Python 3.11+
- Ollama installé localement avec un modèle compatible (ex. `mistral`)

---

## 🔧 Installation

1. Cloner le dépôt :
   ```bash
   git clone https://github.com/votre-utilisateur/IA_V2.git
   cd IA_V2


## ▶️ Lancement du programme
- Lancer le script batch pour démarrer Ollama avec le modèle : - lancement_Mistral_Ollama.bat
- Exécuter le programme principal : python main.py

